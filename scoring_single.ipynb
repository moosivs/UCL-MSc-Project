{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"AHUr7wCetcy0"},"outputs":[],"source":["!pip install datasets\n","!pip install transformers\n","!pip install -U sentence-transformers\n","\n","from datasets import load_dataset\n","from datasets import get_dataset_config_names\n","\n","import torch\n","import numpy as np\n","import pandas as pd\n","import time\n","\n","# For debugging torch\n","import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GFesQAcQtgPY"},"outputs":[],"source":["### Settings ###\n","#@title Dataset Setting \n","dataset = 'COGS' #@param [\"SCAN\", \"CFQ\", \"COGS\"]\n","\n","print(f'Using {dataset} dataset')\n","\n","%cd /content/drive/My Drive/Colab Notebooks/UCL MSc Project/Data\n","\n","data = load_dataset('csv', data_files={'train': f\"./{dataset.lower()}_train.csv\", 'test': f\"./{dataset.lower()}_test.csv\"})\n","\n","train = data['train']\n","test = data['test']\n","\n","if dataset == 'SCAN':\n","  input = 'commands'\n","  target = 'actions'\n","\n","if dataset == 'COGS':\n","  train = train.select(range(len(train)-1))\n","  input = 'source'\n","  target = 'target'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ol28_Sy_tiJ6"},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModelForCausalLM, StoppingCriteria, StoppingCriteriaList, GPTJForCausalLM\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","##### Select model variant #####\n","model_variant = 'gpt-neo-2.7B'\n","print(f\"Running {model_variant}\")\n","\n","tokenizer = AutoTokenizer.from_pretrained(f\"EleutherAI/{model_variant}\")\n","model = AutoModelForCausalLM.from_pretrained(f\"EleutherAI/{model_variant}\")\n","model.to(device)\n","\n","#Additional Info when using cuda\n","if device.type == 'cuda':\n","    print(torch.cuda.get_device_name(0))\n","    print('Memory Usage:')\n","    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n","    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n","\n","# model = GPTJForCausalLM.from_pretrained(\"EleutherAI/gpt-j-6B\", revision=\"float16\", low_cpu_mem_usage=True)\n","# model.to(device)\n","# tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")\n","\n","# # The tokenizer does not have padding token\n","# if tokenizer.pad_token is None:\n","#     tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n","# # Need to resize the model vocab size as we have added an extra token for padding\n","# model.resize_token_embeddings(len(tokenizer))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0bjmfco4tq7_"},"outputs":[],"source":["# scoring\n","def get_prob(candidates_index:list, train_data, test_data, dataset, scoring_model, return_index=True):\n","  # Per test point, score from the training data\n","\n","  desired_tokens = tokenizer(test_data[target]).input_ids\n","  desired_length = len(desired_tokens)\n","\n","  # print(desired_length)\n","\n","  cum_prob = []\n","  index_list = []\n","  for index in candidates_index:\n","    torch.cuda.empty_cache()\n","\n","    index = int(index)\n","    scoring_prompt = ''\n","    scoring_prompt += (f\"{input}:\" + train_data[index][input] + ' ' + f\"{target}:\" + train_data[index][target] + '\\n')\n","    scoring_prompt += (f\"{input}:\" + test_data[input] + ' ' + f\"{target}:{test_data[target]}\")\n","\n","\n","    tokenized_scoring_prompt = tokenizer(scoring_prompt, return_tensors='pt').input_ids[0].to(device)\n","\n","    with torch.no_grad():\n","      check_test = scoring_model(tokenized_scoring_prompt, labels=tokenized_scoring_prompt)\n","\n","    prob = torch.softmax(check_test.logits[-desired_length:], dim=1)\n","    cur_prob = 0\n","    \n","    torch.cuda.empty_cache()\n","    \n","    for j in range(prob.shape[0]):\n","      cur_prob += torch.log(prob[j, desired_tokens[j]])\n","\n","    cum_prob.append(int(cur_prob.cpu().numpy()))\n","    index_list.append(index)\n","\n","  return zip(cum_prob, index_list)\n","\n","\n"]},{"cell_type":"code","source":["# Get top-p and bottom-p samples\n","print(f'Running for {dataset}')\n","\n","top_five_storage = []\n","bottom_five_storage = []\n","\n","index_list = np.load(f'/content/drive/My Drive/Colab Notebooks/UCL MSc Project/Candidate Examples Index/{dataset} Top 75 SBERT Index.npy')\n","for i in range(len(test)):\n","  \n","  print(i)\n","  tmp = np.array(list(get_prob(index_list[i], train, test[i], dataset, model))) # (Score, Index)\n","  \n","  # For cum prob\n","  sorted_score = tmp[tmp[:, 0].argsort()][::-1] # Descending order\n","  top_five = list(sorted_score[:5, 1]) # 1st 2nd 3rd... get index\n","  bottom_five = list(sorted_score[-5:, 1]) # 45th 46th 47th... get index\n","\n","  top_five_storage.append(top_five)\n","  bottom_five_storage.append(bottom_five)\n","\n","  if i % 250 == 0 and i // 250 >0:\n","    data = {'top_five': top_five_storage, 'bottom_five': bottom_five_storage}\n","\n","    df = pd.DataFrame(data)\n","\n","    df.to_csv(f'/content/drive/My Drive/Colab Notebooks/UCL MSc Project/Top and Bottom Five/{dataset} {i // 250} single individual', index=False)\n","    print(f'saving {dataset} {i // 250}')\n","\n","data = {'top_five': top_five_storage, 'bottom_five': bottom_five_storage}\n","\n","df = pd.DataFrame(data)\n","\n","df.to_csv(f'/content/drive/My Drive/Colab Notebooks/UCL MSc Project/Top and Bottom Five/{dataset} single individual', index=False)\n","print(f'{dataset} Final')"],"metadata":{"id":"TG_DC8BLJNop"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNM8bpXxUNN99N3cV2EDFDO"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}